<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>SMI606: Week 9 — Multiple Logistic Regression</title>
    <meta charset="utf-8" />
    <meta name="author" content="Calum Webb" />
    <meta name="date" content="2024-09-16" />
    <script src="week-09-logistic-regression_files/header-attrs/header-attrs.js"></script>
    <link href="week-09-logistic-regression_files/tile-view/tile-view.css" rel="stylesheet" />
    <script src="week-09-logistic-regression_files/tile-view/tile-view.js"></script>
    <link href="week-09-logistic-regression_files/panelset/panelset.css" rel="stylesheet" />
    <script src="week-09-logistic-regression_files/panelset/panelset.js"></script>
    <script src="week-09-logistic-regression_files/xaringanExtra-progressBar/progress-bar.js"></script>
    <link href="week-09-logistic-regression_files/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <script src="week-09-logistic-regression_files/clipboard/clipboard.min.js"></script>
    <link href="week-09-logistic-regression_files/shareon/shareon.min.css" rel="stylesheet" />
    <script src="week-09-logistic-regression_files/shareon/shareon.min.js"></script>
    <link href="week-09-logistic-regression_files/xaringanExtra-shareagain/shareagain.css" rel="stylesheet" />
    <script src="week-09-logistic-regression_files/xaringanExtra-shareagain/shareagain.js"></script>
    <script src="week-09-logistic-regression_files/mark.js/mark.min.js"></script>
    <link href="week-09-logistic-regression_files/xaringanExtra-search/search.css" rel="stylesheet" />
    <script src="week-09-logistic-regression_files/xaringanExtra-search/search.js"></script>
    <script>window.addEventListener('load', function() { window.xeSearch = new RemarkSearch({"position":"bottom-left","caseSensitive":false,"showIcon":true,"autoSearch":false}) })</script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="css/custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: middle
background-size: contain

&lt;br&gt;&lt;br&gt;&lt;br&gt;

# .tuos_purple[SMI606: Week 9&lt;br&gt;Multiple Logistic Regression]

&lt;br&gt;&lt;br&gt;

**Dr. Calum Webb**&lt;br&gt;
Sheffield Methods Institute, the University of Sheffield.&lt;br&gt;
[c.j.webb@sheffield.ac.uk](mailto:c.j.webb@sheffield.ac.uk)





<div>
<style type="text/css">.xaringan-extra-logo {
width: 180px;
height: 128px;
z-index: 0;
background-image: url(header/smi-logo-white.png);
background-size: contain;
background-repeat: no-repeat;
position: absolute;
top:1em;right:2em;
}
</style>
<script>(function () {
  let tries = 0
  function addLogo () {
    if (typeof slideshow === 'undefined') {
      tries += 1
      if (tries < 10) {
        setTimeout(addLogo, 100)
      }
    } else {
      document.querySelectorAll('.remark-slide-content:not(.inverse):not(.hide_logo)')
        .forEach(function (slide) {
          const logo = document.createElement('div')
          logo.classList = 'xaringan-extra-logo'
          logo.href = null
          slide.appendChild(logo)
        })
    }
  }
  document.addEventListener('DOMContentLoaded', addLogo)
})()</script>
</div>




<style>.panelset{--panel-tab-background: #F8F8F8;--panel-tab-active-background: #F8F8F8;--panel-tab-hover-background: #F8F8F8;}</style>

<style>.xe__progress-bar__container {
  top:0;
  opacity: 1;
  position:absolute;
  right:0;
  left: 0;
}
.xe__progress-bar {
  height: 0.25em;
  background-color: #F8F8F8;
  width: calc(var(--slide-current) / var(--slide-total) * 100%);
}
.remark-visible .xe__progress-bar {
  animation: xe__progress-bar__wipe 200ms forwards;
  animation-timing-function: cubic-bezier(.86,0,.07,1);
}
@keyframes xe__progress-bar__wipe {
  0% { width: calc(var(--slide-previous) / var(--slide-total) * 100%); }
  100% { width: calc(var(--slide-current) / var(--slide-total) * 100%); }
}</style>












---
class: middle

.pull-left[


]
.pull-right[

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

# Sign In



]
---
class: middle

## Learning Objectives

.panelset[

.panel[.panel-name[What will I learn?]

By the end of this week you will:

* Be able to identify research questions suited to logistic regression.

* Be able to describe (at a basic level) how logistic regression works and what it can be used for.

* Be able to estimate logistic regression models in `R` using the `glm()` function.

* Be able to check the fit of logistic regression models in `R` using pseudo- `\(R^2\)` statistics, model accuracy, and `\(k\)`-fold cross-validation.

* Be able to check whether your logistic regression model violates any assumptions of general linear regression.


]

.panel[.panel-name[How does this week fit into my course?]

* Logistic regression opens up a world of possible research questions that couldn't be adequately explored with a linear regression model.

* Your knowledge of model assumptions in general linear models will now be complete, enabling you to conduct quantitative research robustly. 


]


]



???


---

class: inverse, middle

Week 9: Logistic Regression — Part I
# What is logistic regression and why learn it?




---

class: inverse, middle

### Multiple linear regression is great... But what if the thing we're interested in isn't on a continuous scale?

(Let alone one with nice normally distributed residuals...)

---

background-color: white

## Wooclap activity

.pull-left[

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

#### What things are you interested in researching that aren't on a continuous scale?

Join the wooclap activity by clicking [this link](https://app.wooclap.com/events/AXUMRY/questions/66e8406bafc80076ce296f5d), or scanning the QR code on the right, and try and contribute at least one variable that you would be interested in analysing but either can't be measured on, or you haven't seen measured on, a continuous scale.

Event ID: **AXUMRY**


]

.pull-right[

&lt;img src="images/smi606-week-9-wooclap-1.png" width="100%" /&gt;

]


---

# Predicting binary outcomes

.pull-left[
We can use linear regression to predict binary outcomes. This is called an LPM — a __linear probability model__ (not to be confused with a linear panel model!)


```r
plm_mod &lt;- lm(data = tv_licenses, formula = tv_license ~ age)

summary(plm_mod)
```

```
## 
## Call:
## lm(formula = tv_license ~ age, data = tv_licenses)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.10876 -0.21049 -0.00056  0.21406  0.84565 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.444497   0.059934  -7.416 1.26e-12 ***
## age          0.018714   0.001082  17.295  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3538 on 298 degrees of freedom
## Multiple R-squared:  0.5009,	Adjusted R-squared:  0.4993 
## F-statistic: 299.1 on 1 and 298 DF,  p-value: &lt; 2.2e-16
```

.small[Every __1 year increase in age__ is associated with a __1.87 percentage point increase__ in the probability of owning a TV license.]

]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-4-1.png" width="500" height="450" /&gt;

]

---

# Predicting binary outcomes

.pull-left[


```r
summary(plm_mod)
```

```
## 
## Call:
## lm(formula = tv_license ~ age, data = tv_licenses)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.10876 -0.21049 -0.00056  0.21406  0.84565 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.444497   0.059934  -7.416 1.26e-12 ***
## age          0.018714   0.001082  17.295  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3538 on 298 degrees of freedom
## Multiple R-squared:  0.5009,	Adjusted R-squared:  0.4993 
## F-statistic: 299.1 on 1 and 298 DF,  p-value: &lt; 2.2e-16
```

But that means that if you are 85 your probability of owning a TV license would be...

`$$\text{tv_license} = -0.44 + 0.0187*85 = 1.1495$$`
__114.95%__??

]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-6-1.png" width="500" height="450" /&gt;

]


---

# Predicting binary outcomes

.pull-left[


```r
summary(plm_mod)
```

```
## 
## Call:
## lm(formula = tv_license ~ age, data = tv_licenses)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.10876 -0.21049 -0.00056  0.21406  0.84565 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.444497   0.059934  -7.416 1.26e-12 ***
## age          0.018714   0.001082  17.295  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3538 on 298 degrees of freedom
## Multiple R-squared:  0.5009,	Adjusted R-squared:  0.4993 
## F-statistic: 299.1 on 1 and 298 DF,  p-value: &lt; 2.2e-16
```

And if you were 20 years old your predicted probability of owning a TV license would be...

`$$\text{tv_license} = -0.44 + 0.0187*20 = -0.066$$`
__-6.6%__??

]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-8-1.png" width="500" height="450" /&gt;

]


---

# Predicting binary outcomes

.pull-left[

When we have binary outcomes to predict what we ideally want to do is constrain out model between either 1 (the thing happened, the person is in the group, etc.) and 0 (the thing didn't happen, the person wasn't in the group, etc.).

For this, we can use __logistic regression__.

]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-9-1.png" width="500" height="450" /&gt;

]

---

# Predicting binary outcomes

.pull-left[

When we have binary outcomes to predict what we ideally want to do is constrain out model between either 1 (the thing happened, the person is in the group, etc.) and 0 (the thing didn't happen, the person wasn't in the group, etc.).

For this, we can use __logistic regression__.

...Much better!

]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-10-1.png" width="500" height="450" /&gt;

]


---

class: inverse, middle

Week 9: Logistic Regression — Part II
# How does logistic regression work?


---

# Logistic regression

.pull-left[
#### How does this magic work?

Unlike multiple linear regression (which usually uses an ordinary least squares estimator), logistic regression uses __Maximum Likelihood__ estimation to calculate the best fitting probabilities for each data point.

Let's talk about what the ML estimator is doing...

]


---

# Logistic regression

.pull-left[

Logistic regression makes use of three things:

#### Odds

What are the odds of a thing happening?

If 150 people own a TV license for every 100 people who don't own a TV license, the odds of someone owning a TV license are 3:2 (usually just written as 1.5)

`$$Odds|A = A/B$$`

#### Log Odds 

The odds can be transformed to their natural log to create 'log odds'

`$$logodds = log(Odds)$$`


]

.pull-right[

This is very useful when combined with the logistic sigmoid function.

#### Logistic sigmoid function

The logistic sigmoid function is a function that returns a value that is always between 0 and 1. It can be defined as:

`$$\frac{e^x}{(1 + e^x)}$$`
When `\(x\)` is our log odds of Y being equal to 1 the logistic sigmoid function returns a __predicted probability__.


]


---

# Logistic regression

#### Example

150 people own TV licenses and 100 people do not. The __odds__ of owning a TV license are equal to `\(150/100 = 1.5\)`.

--

The log odds of owning a TV license are equal to `\(log(1.5) = 0.4054651\)`

--

The predicted probability of owning a TV license can be calculated using the logistic sigmoid function as:

`$$\frac{e^{0.4054651}}{1 + e^{(0.4054651)}}$$`
Or in `R` code: `exp(0.4054651) / (1 + exp(0.4054651))` `= 0.6 = 60%`

--

This means that: if we know the log odds of something we can calculate its predicted probability. The maximum likelihood estimator takes advantage of the properties of log odds to model predicted probabilities that Y = 1 conditional on values of X (__Y=1|X__).

---

# Logistic regression

.pull-left[

#### Visual Explanation

Let's start off with our raw data. Along the top we have the people who do own a TV license (1), along the bottom we have people who do not own a TV license (0).


]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-11-1.png" width="500" height="450" /&gt;

]

---

# Logistic regression

.pull-left[

#### Visual Explanation

Let's start off with our raw data. Along the top we have the people who do own a TV license (1), along the bottom we have people who do not own a TV license (0).

&lt;hr&gt;

Maximum Likelihood is an iterative method, so let's start our first set of predictions at the general odds of owning a TV license (1.127 to 1) before we start to adjust the odds by age.




]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-12-1.png" width="500" height="450" /&gt;

]


---

# Logistic regression

.pull-left[

#### Visual Explanation

Maximum Likelihood is an iterative method, so let's start our first set of predictions at the general odds of owning a TV license (1.127 to 1) before we start to adjust the odds by age.

&lt;hr&gt;

We can then convert our odds to log odds. The log odds equal 0.1201447. 

We also log our real data 

* log(1) = 0
* log(0) = -Infinity




]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-13-1.png" width="500" height="450" /&gt;

]


---

# Logistic regression

.pull-left[

#### Visual Explanation

We can then convert our odds to log odds. The log odds equal 0.1201447. 

We also log our real data 

* log(1) = 0
* log(0) = -Infinity

&lt;hr&gt;

We cannot really use negative infinity for anything, so we map our data points to the closest position on the line. 

]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-14-1.png" width="500" height="450" /&gt;

]


---

# Logistic regression

.pull-left[

#### Visual Explanation

We cannot really use negative infinity for anything, so we map our data points to the closest position on the line. 

&lt;hr&gt;

Now we've assigned each data point to its closest position on a line, we can give it a new value based on the position of the line. We can then transform these new log odds values back into a predicted probability using the logistic sigmoid function.


]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-15-1.png" width="500" height="450" /&gt;

]


---

# Logistic regression

.pull-left[

#### Visual Explanation

Now we've assigned each data point to its closest position on a line, we can give it a new value based on the position of the line. We can then transform these new log odds values back into a predicted probability using the logistic sigmoid function.

&lt;hr&gt;

We can use the logistic sigmoid function below to calculate the predicted probability for each point on the line. Here, every point has the same value, so the calculation is relatively simple:

`$$P(Y=1|X) = \frac{e^{x}}{(1 + e^{x})} = \frac{e^{0.1201447 + 0*age}}{(1 + e^{0.1201447+0*age})}$$`
Doesn't something look familiar about part of our `\(x\)`?

]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-16-1.png" width="500" height="450" /&gt;

]

---

# Logistic regression

.pull-left[

#### Visual Explanation

`$$P(Y=1|X) = \frac{e^{x}}{(1 + e^{x})} = \frac{e^{0.1201447 + 0*age}}{(1 + e^{0.1201447+0*age})}$$`

Doesn't something look familiar about part of our `\(x\)`?

&lt;hr&gt;

We can then get a picture of how good our predictions were from the real values, similar to how we use residuals in ordinary least squares — these ones are not looking very good, are they?


]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-17-1.png" width="500" height="450" /&gt;

]


---

# Logistic regression

.pull-left[

#### Visual Explanation

We can then get a picture of how good our predictions were from the real values, similar to how we use residuals in ordinary least squares — these ones are not looking very good, are they?

&lt;hr&gt;

Let's go back for another iteration — this time, __let's try giving the line a positive slope__.


]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-18-1.png" width="500" height="450" /&gt;

]

---

# Logistic regression

.pull-left[

#### Visual Explanation

Let's go back for another iteration — this time, __let's try giving the line a positive slope__.

&lt;hr&gt;

Then we can repeat the process.


]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-19-1.png" width="500" height="450" /&gt;

]

---

# Logistic regression

.pull-left[

#### Visual Explanation

Let's go back for another iteration — this time, __let's try giving the line a positive slope__.

&lt;hr&gt;

Then we can repeat the process.

&lt;hr&gt;

Let's map our negative infinity and 0 value data points back to their closest position on the log odds regression line.


]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-20-1.png" width="500" height="450" /&gt;

]


---

# Logistic regression

.pull-left[

#### Visual Explanation

Let's go back for another iteration — this time, __let's try giving the line a positive slope__.

&lt;hr&gt;

Then we can repeat the process.

&lt;hr&gt;

Let's map our negative infinity and 0 value data points back to their closest position on the log odds regression line.

&lt;hr&gt;

Then we just need to convert these new values back into predictions using the logistic sigmoid function.


]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-21-1.png" width="500" height="450" /&gt;

]


---

# Logistic regression

.pull-left[

#### Visual Explanation

Then we just need to convert these new values back into predictions using the logistic sigmoid function.

&lt;hr&gt;

Our logistic sigmoid function is now:

`$$P(Y=1|X) = \frac{e^{x}}{(1 + e^{x})} = \frac{e^{-3.9 + 0.0615*age}}{(1 + e^{-3.9 + 0.0615*age})}$$`



]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-22-1.png" width="500" height="450" /&gt;

]


---

# Logistic regression

.pull-left[

#### Visual Explanation

Our logistic sigmoid function is now:

`$$P(Y=1|X) = \frac{e^{x}}{(1 + e^{x})} = \frac{e^{-3.9 + 0.0615*age}}{(1 + e^{-3.9 + 0.0615*age})}$$`

&lt;hr&gt;

If we wanted to, we could use this to calculate the predicted probability of any given age. For example:

The predicted probability of owning a TV license when age = 80 is:

`$$\frac{e^{-3.9 + 0.0615*80}}{(1 + e^{-3.9 + 0.0615*80})} = 0.7349$$`
Or in `R` code: `exp(-3.9 + 0.0615*80)/(1 + exp(-3.9 + 0.0615*80)) = 0.7349`

]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-23-1.png" width="500" height="450" /&gt;

]


---

# Logistic regression

.pull-left[

#### Visual Explanation

Can we do even better? What happens if we increase the regression line for the log odds even further.


]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-24-1.png" width="500" height="450" /&gt;

]

---

# Logistic regression

.pull-left[

#### Visual Explanation

Can we do even better? What happens if we increase the regression line for the log odds even further.

&lt;hr&gt;

Note that, even though the distance between the points is getting larger in terms of log odds, this does not happen in the predictions due to them always being forced to be between 0 and 1.


]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-25-1.png" width="500" height="450" /&gt;

]

---

# Logistic regression

.pull-left[

#### Visual Explanation

Let's repeat the process. First, let's project all of the points to their closest position on the line.


]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-26-1.png" width="500" height="450" /&gt;

]

---

# Logistic regression

.pull-left[

#### Visual Explanation

Let's repeat the process. First, let's project all of the points to their closest position on the line.

&lt;hr&gt;

Then we (or rather, the Maximum Likelihood Estimator) maps each point to its closest position on the line.


]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-27-1.png" width="500" height="450" /&gt;

]

---

# Logistic regression

.pull-left[

#### Visual Explanation

Let's repeat the process. First, let's project all of the points to their closest position on the line.

&lt;hr&gt;

Then we (or rather, the Maximum Likelihood Estimator) maps each point to its closest position on the line.

&lt;hr&gt;

Then we can convert the resulting values for each point back into a predicted probability using the sigmoid function.


]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-28-1.png" width="500" height="450" /&gt;

]

---

# Logistic regression

.pull-left[

#### Visual Explanation

Now we have another new set of predictions. Note that even though our logistic regression's sigmoid curve changed, our log odds regression remained a straight line (and could still be expressed in log odds as `\(\bar{Y} = B_0 + B_1X ...\)`).


]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-29-1.png" width="500" height="450" /&gt;

]

---

# Logistic regression

.pull-left[

#### Visual Explanation

If these predictions are better than our last iteration, it would make sense to keep them! 

We could try making the line steeper again and see if it improves them further. If not, we could make the line more shallow and keep going until we can't get any better predictions by changing the slope of the log odds regression line. When this happens it is known as __convergence__, and our logistic regression model gives us the outcome in the form of:

`$$log(Odds Y=1|X) = B_0 + B_1X_1 + ... + B_nX_n$$`
Which we can always convert back into predicted probability using the logistic sigmoid function! Pretty cool!

]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-30-1.png" width="500" height="450" /&gt;

]

---

# Logistic regression

.pull-left[

&lt;br&gt;&lt;br&gt;

Don't worry if this is too much maths/doesn't make much sense! The most important thing in this module is knowing how to run and interpret logistic regression models in R (which is very easy!) 

__You can use logistic regression even if you aren't confident using any of the formulas here__ or don't understand how maximum likelihood estimation works (I barely do)!

I wouldn't be doing my job as an educator if I didn't at least try and explain to you how it works!

]

.pull-right[

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-31-1.png" width="500" height="450" /&gt;

]

---

class: inverse, middle

Week 9: Logistic Regression — Part III
# Estimating, interpreting, and communicating logistic regression in `R`.



---

class: middle, inverse

Let's work through an example...

## Who believes the government is hiding evidence of aliens?

---

### Predicting belief in Alien conspiracy theories with logistic regression

.pull-left[


```r
conspiracy_data &lt;- read_rds("conspiracy.rds")
```





```r
conspiracy_data %&gt;%
  janitor::tabyl(consp_alien)
```

```
##  consp_alien    n   percent
##            0 1025 0.6792578
##            1  484 0.3207422
```

]

.pull-right[

#### How true do you think the following statement is: 'The government covers up knowledge of aliens'

(Recoded so that "Definitely true" and "Probably true" = 1, and "Probably false" and "Definitely false = 0)

__Independent Variables__

* Age (`rage`)
* Whether plays video games (`games`): Ref = Doesn't play video games
* Highest education qualification (`hedqual_rec`): Ref = No qualifications
* Openness to new experiences (`openness`)
  * 0 = Lowest openness, 3 = highest openness





]

---

### Predicting belief in Alien conspiracy theories with logistic regression

.pull-left[

#### Estimating a multiple logistic regression model

]

.pull-right[

#### Code


```r
# Model
glm(data = conspiracy_data, 
    formula = consp_alien ~ rage + games + 
                            hedqual_rec + openness, 
    family = binomial(link = "logit"))
```

]


---

### Predicting belief in Alien conspiracy theories with logistic regression

.pull-left[

#### Estimating a multiple logistic regression model

* We need to use the `glm()` function (general linear model), rather than the `lm()` function we used for simple linear regression.

]

.pull-right[

#### Code


```r
# Model
*glm(data = conspiracy_data,
    formula = consp_alien ~ rage + games + 
                            hedqual_rec + openness, 
    family = binomial(link = "logit"))
```

]

---

### Predicting belief in Alien conspiracy theories with logistic regression

.pull-left[

#### Estimating a multiple logistic regression model

* We need to use the `glm()` function (general linear model), rather than the `lm()` function we used for simple linear regression.

* We add in our formula in exactly the same way — our dependent variable should be a binary categorical variable which can be a factor, character, numeric, or logical class. The value being predicted will be __1__ for a __numeric__ class, __TRUE__ for a __logical__ class, the __highest value/non reference level__ in a __factor__ class. It will not work for a character class. If in doubt, just recode into a binary numeric!

]

.pull-right[

#### Code


```r
# Model
glm(data = conspiracy_data, 
*   formula = consp_alien ~ rage + games +
*                           hedqual_rec + openness,
    family = binomial(link = "logit"))
```

]


---

### Predicting belief in Alien conspiracy theories with logistic regression

.pull-left[

#### Estimating a multiple logistic regression model

* We need to use the `glm()` function (general linear model), rather than the `lm()` function we used for simple linear regression.

* We add in our formula in exactly the same way — our dependent variable should be a binary categorical variable which can be a factor, character, numeric, or logical class. The value being predicted will be __1__ for a __numeric__ class, __TRUE__ for a __logical__ class, the __highest value/non reference level__ in a __factor__ class. It will not work for a character class. If in doubt, just recode into a binary numeric!

* Finally, and __importantly__ we add `binomial(link = "logit")` to the `family = ` argument. This tells `glm()` that we want a logistic regression, not a standard linear regression.

]

.pull-right[

#### Code


```r
glm(data = conspiracy_data, 
    formula = consp_alien ~ rage + games + 
                            hedqual_rec + openness, 
*   family = binomial(link = "logit"))
```

]


---

### Predicting belief in Alien conspiracy theories with logistic regression

.pull-left-big[

```r
alien_model &lt;- glm(data = conspiracy_data, 
                    formula = consp_alien ~ rage + games + 
                                            hedqual_rec + openness, 
                    family = binomial(link = "logit")) 

summary(alien_model)
```

```
## 
## Call:
## glm(formula = consp_alien ~ rage + games + hedqual_rec + openness, 
##     family = binomial(link = "logit"), data = conspiracy_data)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.3461  -0.9378  -0.6988   1.2889   2.1832  
## 
## Coefficients:
##                                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                     -0.003565   0.290870  -0.012  0.99022    
## rage                            -0.007881   0.003547  -2.222  0.02631 *  
## gamesYes                        -0.008412   0.127939  -0.066  0.94758    
## hedqual_recLevel 1 quals        -0.041263   0.246457  -0.167  0.86704    
## hedqual_recGCSEs/O levels       -0.445559   0.186221  -2.393  0.01673 *  
## hedqual_recA levels             -0.649653   0.200278  -3.244  0.00118 ** 
## hedqual_recHigher Ed, no degree -0.900748   0.203448  -4.427 9.54e-06 ***
## hedqual_recFirst degree         -1.373859   0.220424  -6.233 4.58e-10 ***
## hedqual_recPostgraduate degree  -1.844309   0.277238  -6.652 2.88e-11 ***
## openness                         0.215493   0.077718   2.773  0.00556 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1849.1  on 1468  degrees of freedom
## Residual deviance: 1764.4  on 1459  degrees of freedom
##   (40 observations deleted due to missingness)
## AIC: 1784.4
## 
## Number of Fisher Scoring iterations: 4
```
]

.pull-right-small[

__Estimates__

Estimates are now either the base log odds (Intercept) or the __change in log odds for a 1 unit change in X__.

__p-values__

p-values operate in the same way (albeit with a z-statistic rather than a t-statistic) and __test the hypothesis that the change in log odds associated with a 1-unit increase in X is equal to 0__.

But how do I communicate changes in log odds!?

]


---

### Predicting belief in Alien conspiracy theories with logistic regression

.pull-left-big[

```r
alien_model &lt;- glm(data = conspiracy_data, 
                    formula = consp_alien ~ rage + games + 
                                            hedqual_rec + openness, 
                    family = binomial(link = "logit")) 

summary(alien_model)
```

```
## 
## Call:
## glm(formula = consp_alien ~ rage + games + hedqual_rec + openness, 
##     family = binomial(link = "logit"), data = conspiracy_data)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.3461  -0.9378  -0.6988   1.2889   2.1832  
## 
## Coefficients:
##                                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                     -0.003565   0.290870  -0.012  0.99022    
## rage                            -0.007881   0.003547  -2.222  0.02631 *  
## gamesYes                        -0.008412   0.127939  -0.066  0.94758    
## hedqual_recLevel 1 quals        -0.041263   0.246457  -0.167  0.86704    
## hedqual_recGCSEs/O levels       -0.445559   0.186221  -2.393  0.01673 *  
## hedqual_recA levels             -0.649653   0.200278  -3.244  0.00118 ** 
## hedqual_recHigher Ed, no degree -0.900748   0.203448  -4.427 9.54e-06 ***
## hedqual_recFirst degree         -1.373859   0.220424  -6.233 4.58e-10 ***
## hedqual_recPostgraduate degree  -1.844309   0.277238  -6.652 2.88e-11 ***
## openness                         0.215493   0.077718   2.773  0.00556 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1849.1  on 1468  degrees of freedom
## Residual deviance: 1764.4  on 1459  degrees of freedom
##   (40 observations deleted due to missingness)
## AIC: 1784.4
## 
## Number of Fisher Scoring iterations: 4
```
]

.pull-right-small[

__Odds Ratios/ Exponentiated Coefficients__

If we exponentiate (using `exp()`) the change in log odds associated with 1-unit increases in our independent variables, we get something called an __odds ratio__.

This __odds ratio__ tells us the multiplicative change in the odds for a 1-unit increase — in other words __how many times as likely is it that Y = 1 when when the independent variable increases by 1__.

For example, __for a 1-unit increase in openness__ __the odds of believing in alien conspiracy theories increases by__ exp(0.215493) = __1.24 times__, or by around 24%.

]

---

### Predicting belief in Alien conspiracy theories with logistic regression

.pull-left-big[

```r
alien_model &lt;- glm(data = conspiracy_data, 
                    formula = consp_alien ~ rage + games + 
                                            hedqual_rec + openness, 
                    family = binomial(link = "logit")) 

summary(alien_model)
```

```
## 
## Call:
## glm(formula = consp_alien ~ rage + games + hedqual_rec + openness, 
##     family = binomial(link = "logit"), data = conspiracy_data)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.3461  -0.9378  -0.6988   1.2889   2.1832  
## 
## Coefficients:
##                                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                     -0.003565   0.290870  -0.012  0.99022    
## rage                            -0.007881   0.003547  -2.222  0.02631 *  
## gamesYes                        -0.008412   0.127939  -0.066  0.94758    
## hedqual_recLevel 1 quals        -0.041263   0.246457  -0.167  0.86704    
## hedqual_recGCSEs/O levels       -0.445559   0.186221  -2.393  0.01673 *  
## hedqual_recA levels             -0.649653   0.200278  -3.244  0.00118 ** 
## hedqual_recHigher Ed, no degree -0.900748   0.203448  -4.427 9.54e-06 ***
## hedqual_recFirst degree         -1.373859   0.220424  -6.233 4.58e-10 ***
## hedqual_recPostgraduate degree  -1.844309   0.277238  -6.652 2.88e-11 ***
## openness                         0.215493   0.077718   2.773  0.00556 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1849.1  on 1468  degrees of freedom
## Residual deviance: 1764.4  on 1459  degrees of freedom
##   (40 observations deleted due to missingness)
## AIC: 1784.4
## 
## Number of Fisher Scoring iterations: 4
```
]

.pull-right-small[

__Odds Ratios/ Exponentiated Coefficients__

Negative odds ratios can be a little bit more tricky to interpret, but are not too difficult with a bit of work.

For example, the multiplicative change in odds associated with having a postgraduate degree is exp(-1.844309) or __0.158__. 

This means that __the odds of believing in alien conspiracy theories decrease by 84.2% among those with higher education degrees, compared to those with no qualifications__ (1 - exp(-1.844309) or 1 - 0.158)

]


---

### Predicting belief in Alien conspiracy theories with logistic regression

#### Quickly Adding Odds Ratios to your Model Output using `broom` and `mutate`

* Use `broom::tidy()` to turn your model output into a tidy tibble



```r
# Convert model to tibble with broom::tidy
tidy_model &lt;- broom::tidy(alien_model)
tidy_model
```

```
## # A tibble: 10 × 5
##    term                            estimate std.error statistic  p.value
##    &lt;chr&gt;                              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 (Intercept)                     -0.00356   0.291     -0.0123 9.90e- 1
##  2 rage                            -0.00788   0.00355   -2.22   2.63e- 2
##  3 gamesYes                        -0.00841   0.128     -0.0657 9.48e- 1
##  4 hedqual_recLevel 1 quals        -0.0413    0.246     -0.167  8.67e- 1
##  5 hedqual_recGCSEs/O levels       -0.446     0.186     -2.39   1.67e- 2
##  6 hedqual_recA levels             -0.650     0.200     -3.24   1.18e- 3
##  7 hedqual_recHigher Ed, no degree -0.901     0.203     -4.43   9.54e- 6
##  8 hedqual_recFirst degree         -1.37      0.220     -6.23   4.58e-10
##  9 hedqual_recPostgraduate degree  -1.84      0.277     -6.65   2.88e-11
## 10 openness                         0.215     0.0777     2.77   5.56e- 3
```

---

### Predicting belief in Alien conspiracy theories with logistic regression

#### Quickly Adding Odds Ratios to your Model Output using `broom` and `mutate`

* Use `broom::tidy()` to turn your model output into a tidy tibble

* Use `mutate` to create an extra column of exponentiated coefficients (a.k.a. odds ratios)



```r
# Create odds ratios column
tidy_model &lt;- tidy_model %&gt;%
  mutate(
*   odds_ratios = exp(estimate)
  )

tidy_model
```

```
## # A tibble: 10 × 6
##    term                        estimate std.error statistic  p.value odds_ratios
##    &lt;chr&gt;                          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;
##  1 (Intercept)                 -0.00356   0.291     -0.0123 9.90e- 1       0.996
##  2 rage                        -0.00788   0.00355   -2.22   2.63e- 2       0.992
##  3 gamesYes                    -0.00841   0.128     -0.0657 9.48e- 1       0.992
##  4 hedqual_recLevel 1 quals    -0.0413    0.246     -0.167  8.67e- 1       0.960
##  5 hedqual_recGCSEs/O levels   -0.446     0.186     -2.39   1.67e- 2       0.640
##  6 hedqual_recA levels         -0.650     0.200     -3.24   1.18e- 3       0.522
##  7 hedqual_recHigher Ed, no d… -0.901     0.203     -4.43   9.54e- 6       0.406
##  8 hedqual_recFirst degree     -1.37      0.220     -6.23   4.58e-10       0.253
##  9 hedqual_recPostgraduate de… -1.84      0.277     -6.65   2.88e-11       0.158
## 10 openness                     0.215     0.0777     2.77   5.56e- 3       1.24
```

---

### Predicting belief in Alien conspiracy theories with logistic regression

#### Quickly Adding Odds Ratios to your Model Output using `broom` and `mutate`

* Use `broom::tidy()` to turn your model output into a tidy tibble

* Use `mutate` to create an extra column of exponentiated coefficients (a.k.a. odds ratios)



```r
# Create odds ratios column
tidy_model &lt;- tidy_model %&gt;%
  mutate(
*   odds_ratios = exp(estimate)
  )

tidy_model
```

```
## # A tibble: 10 × 6
##    term                        estimate std.error statistic  p.value odds_ratios
##    &lt;chr&gt;                          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;
##  1 (Intercept)                 -0.00356   0.291     -0.0123 9.90e- 1       0.996
##  2 rage                        -0.00788   0.00355   -2.22   2.63e- 2       0.992
##  3 gamesYes                    -0.00841   0.128     -0.0657 9.48e- 1       0.992
##  4 hedqual_recLevel 1 quals    -0.0413    0.246     -0.167  8.67e- 1       0.960
##  5 hedqual_recGCSEs/O levels   -0.446     0.186     -2.39   1.67e- 2       0.640
##  6 hedqual_recA levels         -0.650     0.200     -3.24   1.18e- 3       0.522
##  7 hedqual_recHigher Ed, no d… -0.901     0.203     -4.43   9.54e- 6       0.406
##  8 hedqual_recFirst degree     -1.37      0.220     -6.23   4.58e-10       0.253
##  9 hedqual_recPostgraduate de… -1.84      0.277     -6.65   2.88e-11       0.158
## 10 openness                     0.215     0.0777     2.77   5.56e- 3       1.24
```

.center[What was the associated change in the odds of believing the government hides information related to aliens for a 1 year increase in age?]

---

### Predicting belief in Alien conspiracy theories with logistic regression

.pull-left[

What about if we want to look at the predictions themselves, not just the change in odds?

]

.pull-right[



]

---

### Predicting belief in Alien conspiracy theories with logistic regression

.pull-left[

What about if we want to look at the predictions themselves, not just the change in odds?

We can use a very nice package called `ggeffects` to plot the predictied probabilities for different independent variables, while keeping the value of other independent variables constant at their mean.

First, load the `ggeffects` library.

]

.pull-right[


```r
library(ggeffects)
```


]

---

### Predicting belief in Alien conspiracy theories with logistic regression

.pull-left[

What about if we want to look at the predictions themselves, not just the change in odds?

We can use a very nice package called `ggeffects` to plot the predictied probabilities for different independent variables, while keeping the value of other independent variables constant at their mean.

First, load the `ggeffects` library.

Then, run the `ggeffect` function; make sure to specify the variable you want predictions for in the `terms` argument. Here, I want predictions for `openness`. This will give me some text output for a few possible values of openness.

]

.pull-right[


```r
library(ggeffects)

*ggeffect(alien_model, terms = "openness")
```

```
## # Predicted probabilities of Conspiracy beliefs - government covers up knowledge of aliens
## 
## openness | Predicted |       95% CI
## -----------------------------------
##     0.00 |      0.24 | [0.20, 0.30]
##     0.33 |      0.26 | [0.22, 0.30]
##     0.67 |      0.27 | [0.24, 0.31]
##     1.00 |      0.29 | [0.26, 0.32]
##     1.67 |      0.32 | [0.29, 0.34]
##     2.00 |      0.33 | [0.30, 0.36]
##     2.33 |      0.35 | [0.31, 0.38]
##     3.00 |      0.38 | [0.33, 0.44]
```


]


---

### Predicting belief in Alien conspiracy theories with logistic regression

.pull-left[

What about if we want to look at the predictions themselves, not just the change in odds?

We can use a very nice package called `ggeffects` to plot the predictied probabilities for different independent variables, while keeping the value of other independent variables constant at their mean.

First, load the `ggeffects` library.

Then, run the `ggeffect` function; make sure to specify the variable you want predictions for in the `terms` argument. Here, I want predictions for `openness`. This will give me some text output for a few possible values of openness.

We can add a `plot()` function after this with a `%&gt;%` to turn this into a ggplot! You can even customise it by using `ggplot` functions like you would normally. 

]

.pull-right[


```r
library(ggeffects)

ggeffect(alien_model, terms = "openness") %&gt;%
* plot()
```

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-49-1.png" width="500" height="400" /&gt;


]


---

### Predicting belief in Alien conspiracy theories with logistic regression

.pull-left[

The plot you get will differ depending on whether your independent variable is categorical/ordinal or continuous.

]

.pull-right[


```r
library(ggeffects)

ggeffect(alien_model, terms = "hedqual_rec") %&gt;%
  plot() +
  coord_flip()
```

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-51-1.png" width="500" height="380" /&gt;


]

---

class: inverse, middle

Week 9: Logistic Regression — Part IV
# Logistic regression model fit and accuracy.

---


class: inverse, middle

## But wait, what happened to our R-squared statistic? How good is our model overall?

---

# Model fit/accuracy

.pull-left[
With logistic regression we cannot calculate an `\(R^2\)` value for model fit in the same way we would for a multiple linear regression model.



]


---

# Model fit/accuracy

.pull-left[

#### Pseudo `\(R^2\)`

One option is to use one of [a range of Pseudo-](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/) `\(R^2\)`s. However, these do not have quite as straightforward a definition as OLS `\(R^2\)`.

* __McFadden `\(R^2\)`__: Values between 0.2 and 0.4 represent excellent fit to the data ([Heshner &amp; Stopher, 1979](https://books.google.co.uk/books/about/Behavioural_Travel_Modelling.html?id=jqEOAAAAQAAJ&amp;redir_esc=y))
* __Cox &amp; Snell `\(R^2\)`__: No exact interpretation. Closer to 1 = better fit.
* __Nagelkerke `\(R^2\)`__: No exact interpretation. Closer to 1 = better fit.
* __Efron `\(R^2\)`__: Based on the difference between the predicted probabilities and actual responses. Closer to 1 = better fit.


]


.pull-right[


```r
pseudo_r2s_alien &lt;- DescTools::PseudoR2(alien_model, which = c("McFadden", "CoxSnell", "Nagelkerke", "Efron"))

tibble(
  r2_names = names(pseudo_r2s_alien),
  r2_vals = pseudo_r2s_alien
)
```

```
## # A tibble: 4 × 2
##   r2_names   r2_vals
##   &lt;chr&gt;        &lt;dbl&gt;
## 1 McFadden    0.0458
## 2 CoxSnell    0.0560
## 3 Nagelkerke  0.0782
## 4 Efron       0.0554
```

]

---

# Model fit/accuracy

.pull-left[

#### Pseudo `\(R^2\)`

One option is to use one of [a range of Pseudo- ](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/) `\(R^2\)`s. However, these do not have quite as straightforward a definition as OLS `\(R^2\)`.

* __McFadden `\(R^2\)`__: Values between 0.2 and 0.4 represent excellent fit to the data ([Heshner &amp; Stopher, 1979](https://books.google.co.uk/books/about/Behavioural_Travel_Modelling.html?id=jqEOAAAAQAAJ&amp;redir_esc=y))
* __Cox &amp; Snell `\(R^2\)`__: No exact interpretation. Closer to 1 = better fit.
* __Nagelkerke `\(R^2\)`__: No exact interpretation. Closer to 1 = better fit.
* __Efron `\(R^2\)`__: Based on the difference between the predicted probabilities and actual responses. Closer to 1 = better fit.


]


.pull-right[

However, Pseudo- `\(R^2\)` values are of limited value for logistic regression — they can often be useful for __comparing the goodness of fit of different models__, but are not as useful as OLS `\(R^2\)` for explaining how well a model fits the data overall ([Hosmer, Lemeshow &amp; Sturdivant, 2013](https://books.google.co.uk/books?hl=en&amp;lr=&amp;id=64JYAwAAQBAJ&amp;oi=fnd&amp;pg=PR13&amp;dq=info:QYB4u56LccYJ:scholar.google.com&amp;ots=DteR616thH&amp;sig=ilP_3paE7jN8FhOxoy05eR9erwI&amp;redir_esc=y#v=onepage&amp;q&amp;f=false)).

However, we have two additional tools at our disposal for assessing our models: __accuracy__ and __cross-validation__.

]


---

# Model fit/accuracy

.pull-left[

#### Accuracy

In the context of logistic regression, __accuracy__ refers to whether our model's predictions are __able to correctly classify the underlying data__. 


]

---

# Model fit/accuracy

.pull-left[

#### Accuracy

In the context of logistic regression, __accuracy__ refers to whether our model's predictions are __able to correctly classify the underlying data__. 

The first stage is to calculate our predictions.

* We start by using the `mutate` function to create a new column called `pred_consp_alien` using the `predict` function. 
  * The first argument (`alien_model`) tells `R` the model to be used for prediction.
  * The second argument (`type = "response"`) tells `R` we want the predicted probability, not the logodds.
  * The third argument (`newdata = conspiracy_data`) provides `R` with the data that holds the independent variables required for the prediction of each case. 


]

.pull-right[


```r
conspiracy_data &lt;- conspiracy_data %&gt;%
  mutate(
    pred_consp_alien = predict(alien_model, 
                               type = "response", 
                               newdata = conspiracy_data)
  ) 

conspiracy_data %&gt;%
  select(consp_alien, pred_consp_alien)
```

```
## # A tibble: 1,509 × 2
##    consp_alien pred_consp_alien
##          &lt;dbl&gt;            &lt;dbl&gt;
##  1           1            0.338
##  2           1            0.376
##  3           1            0.516
##  4           1            0.440
##  5           1            0.347
##  6           1            0.431
##  7           1            0.403
##  8           0            0.521
##  9           0           NA    
## 10           0            0.374
## # ℹ 1,499 more rows
```


]

---

# Model fit/accuracy

.pull-left[

#### Accuracy

The second stage is to convert our predicted probabilities into predicted outcomes. 

* I use the `mutate` function again, this time to overwrite the `pred_consp_alien` variable with the outcome from a `case_when` function.
* The `case_when` function does the following:
  * Any `NA` predictions (because of missing independent variables) stay as missing (`NA_real_`).
  * When `pred_consp_alien` is greater than or equal to 0.5, it now becomes 1.
  * Else, `pred_cons_alien` is equal to 0 (whenever it's less than 0.5).
  
I then check the results with a temporary `select()`.

]

.pull-right[


```r
conspiracy_data &lt;- conspiracy_data %&gt;%
  mutate(
    pred_consp_alien = case_when(is.na(pred_consp_alien) ~ NA_real_,
                                 pred_consp_alien &gt;= 0.5 ~ 1,
                                 TRUE ~ 0)
  )

conspiracy_data %&gt;%
  select(consp_alien, pred_consp_alien)
```

```
## # A tibble: 1,509 × 2
##    consp_alien pred_consp_alien
##          &lt;dbl&gt;            &lt;dbl&gt;
##  1           1                0
##  2           1                0
##  3           1                1
##  4           1                0
##  5           1                0
##  6           1                0
##  7           1                0
##  8           0                1
##  9           0               NA
## 10           0                0
## # ℹ 1,499 more rows
```


]

---

# Model fit/accuracy

.pull-left[

#### Accuracy

Now I can calculate the accuracy of my model against the real data. A quick way to do this and get a collection of relevant statistics is using the `caret` package's `confusionMatrix` function.

* Note that I first change the predictions and original data into factors, and make 0 the reference level. This is because the `caret::confusionMatrix` function only accepts factor type variables.

]

.pull-right[


```r
library(caret)

confusionMatrix(
  data = relevel(factor( conspiracy_data$pred_consp_alien ), 
                     ref = "0"),
  reference = relevel(factor( conspiracy_data$consp_alien ), 
                          ref = "0"),
)
```

```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 961 443
##          1  33  32
##                                           
##                Accuracy : 0.676           
##                  95% CI : (0.6514, 0.6999)
##     No Information Rate : 0.6767          
##     P-Value [Acc &gt; NIR] : 0.5346          
##                                           
##                   Kappa : 0.0441          
##                                           
##  Mcnemar's Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.96680         
##             Specificity : 0.06737         
##          Pos Pred Value : 0.68447         
##          Neg Pred Value : 0.49231         
##              Prevalence : 0.67665         
##          Detection Rate : 0.65419         
##    Detection Prevalence : 0.95575         
##       Balanced Accuracy : 0.51708         
##                                           
##        'Positive' Class : 0               
## 
```


]


---

# Model fit/accuracy

.pull-left[

#### Accuracy

There is a lot of information here, but for this class I just want to focus on four things:

* The __Confusion Matrix/Classification Table__

* The __Accuracy__

* The __No Information Rate__

* The __Acc &gt; NIR hypothesis test result__

]

.pull-right[


```r
library(caret)

confusionMatrix(
  data = relevel(factor( conspiracy_data$pred_consp_alien ), 
                     ref = "0"),
  reference = relevel(factor( conspiracy_data$consp_alien ), 
                          ref = "0"),
)
```

```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 961 443
##          1  33  32
##                                           
##                Accuracy : 0.676           
##                  95% CI : (0.6514, 0.6999)
##     No Information Rate : 0.6767          
##     P-Value [Acc &gt; NIR] : 0.5346          
##                                           
##                   Kappa : 0.0441          
##                                           
##  Mcnemar's Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.96680         
##             Specificity : 0.06737         
##          Pos Pred Value : 0.68447         
##          Neg Pred Value : 0.49231         
##              Prevalence : 0.67665         
##          Detection Rate : 0.65419         
##    Detection Prevalence : 0.95575         
##       Balanced Accuracy : 0.51708         
##                                           
##        'Positive' Class : 0               
## 
```


]

---

# Model fit/accuracy

.pull-left[

#### Accuracy

There is a lot of information here, but for this class I just want to focus on four things:

* The __Confusion Matrix/Classification Table__

The 2x2 table at the top of the output tells us how many values were correctly predicted (0 = 0 / 1 = 1) and how many were incorrectly predicted (false positives, predicted 1 when it should be 0; false negatives, predicted 0 when it should be 1). You can see that we had quite a large number of false negatives with this model: __443__!

* The __Accuracy__

* The __No Information Rate__

* The __Acc &gt; NIR hypothesis test result__

]

.pull-right[


```r
library(caret)

confusionMatrix(
  data = relevel(factor( conspiracy_data$pred_consp_alien ), 
                     ref = "0"),
  reference = relevel(factor( conspiracy_data$consp_alien ), 
                          ref = "0"),
)
```

```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 961 443
##          1  33  32
##                                           
##                Accuracy : 0.676           
##                  95% CI : (0.6514, 0.6999)
##     No Information Rate : 0.6767          
##     P-Value [Acc &gt; NIR] : 0.5346          
##                                           
##                   Kappa : 0.0441          
##                                           
##  Mcnemar's Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.96680         
##             Specificity : 0.06737         
##          Pos Pred Value : 0.68447         
##          Neg Pred Value : 0.49231         
##              Prevalence : 0.67665         
##          Detection Rate : 0.65419         
##    Detection Prevalence : 0.95575         
##       Balanced Accuracy : 0.51708         
##                                           
##        'Positive' Class : 0               
## 
```


]


---

# Model fit/accuracy

.pull-left[

#### Accuracy

There is a lot of information here, but for this class I just want to focus on four things:

* The __Confusion Matrix/Classification Table__

* The __Accuracy__

Accuracy is a straightforward calculation of the proportion of classifications that the model got correct. 961 + 32 predictions were correct (993), and 443 + 33 predictions were incorrect (476). This means that 993 out of 1469 cases were correctly predicted by our model (67.6%).

* The __No Information Rate__

* The __Acc &gt; NIR hypothesis test result__

]

.pull-right[


```r
library(caret)

confusionMatrix(
  data = relevel(factor( conspiracy_data$pred_consp_alien ), 
                     ref = "0"),
  reference = relevel(factor( conspiracy_data$consp_alien ), 
                          ref = "0"),
)
```

```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 961 443
##          1  33  32
##                                           
##                Accuracy : 0.676           
##                  95% CI : (0.6514, 0.6999)
##     No Information Rate : 0.6767          
##     P-Value [Acc &gt; NIR] : 0.5346          
##                                           
##                   Kappa : 0.0441          
##                                           
##  Mcnemar's Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.96680         
##             Specificity : 0.06737         
##          Pos Pred Value : 0.68447         
##          Neg Pred Value : 0.49231         
##              Prevalence : 0.67665         
##          Detection Rate : 0.65419         
##    Detection Prevalence : 0.95575         
##       Balanced Accuracy : 0.51708         
##                                           
##        'Positive' Class : 0               
## 
```


]


---

# Model fit/accuracy

.pull-left[

#### Accuracy

There is a lot of information here, but for this class I just want to focus on four things:

* The __Confusion Matrix/Classification Table__

* The __Accuracy__

* The __No Information Rate__

The No Information Rate is the proportion of observations we would expect to get correct by guessing without any additional information; equal to the proportion of the largest group (994 / 1469 = 67.67%).  

* The __Acc &gt; NIR hypothesis test result__

]

.pull-right[


```r
library(caret)

confusionMatrix(
  data = relevel(factor( conspiracy_data$pred_consp_alien ), 
                     ref = "0"),
  reference = relevel(factor( conspiracy_data$consp_alien ), 
                          ref = "0"),
)
```

```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 961 443
##          1  33  32
##                                           
##                Accuracy : 0.676           
##                  95% CI : (0.6514, 0.6999)
##     No Information Rate : 0.6767          
##     P-Value [Acc &gt; NIR] : 0.5346          
##                                           
##                   Kappa : 0.0441          
##                                           
##  Mcnemar's Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.96680         
##             Specificity : 0.06737         
##          Pos Pred Value : 0.68447         
##          Neg Pred Value : 0.49231         
##              Prevalence : 0.67665         
##          Detection Rate : 0.65419         
##    Detection Prevalence : 0.95575         
##       Balanced Accuracy : 0.51708         
##                                           
##        'Positive' Class : 0               
## 
```


]


---

# Model fit/accuracy

.pull-left[

#### Accuracy

There is a lot of information here, but for this class I just want to focus on four things:

* The __Confusion Matrix/Classification Table__

* The __Accuracy__

* The __No Information Rate__

* The __Acc &gt; NIR hypothesis test result__

Lastly, we have a hypothesis test for the hypothesis that our model's accuracy is not greater than the No Information Rate. A p-value less than 0.05 indicates our accuracy is significantly better than the No Information Rate.

]

.pull-right[


```r
library(caret)

confusionMatrix(
  data = relevel(factor( conspiracy_data$pred_consp_alien ), 
                     ref = "0"),
  reference = relevel(factor( conspiracy_data$consp_alien ), 
                          ref = "0"),
)
```

```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0 961 443
##          1  33  32
##                                           
##                Accuracy : 0.676           
##                  95% CI : (0.6514, 0.6999)
##     No Information Rate : 0.6767          
##     P-Value [Acc &gt; NIR] : 0.5346          
##                                           
##                   Kappa : 0.0441          
##                                           
##  Mcnemar's Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.96680         
##             Specificity : 0.06737         
##          Pos Pred Value : 0.68447         
##          Neg Pred Value : 0.49231         
##              Prevalence : 0.67665         
##          Detection Rate : 0.65419         
##    Detection Prevalence : 0.95575         
##       Balanced Accuracy : 0.51708         
##                                           
##        'Positive' Class : 0               
## 
```


]

---

# Model fit/accuracy

.pull-left[

#### Accuracy Weaknesses

While intuitive, we should be cautious about relying only on accuracy for measuring model fit.

Accuracy alone __doesn't tell us how good our predicted probabilities are__. Most of our predicted probabilities could be very marginal.

This means that small amounts of random bias or error in our specific sample could make our model perform much better in an accuracy test than it would in the population.


]

.pull-right[


```
## # A tibble: 11 × 2
##    consp_alien pred_consp_alien
##          &lt;dbl&gt;            &lt;dbl&gt;
##  1           0            0.374
##  2           0            0.153
##  3           1            0.287
##  4           0            0.251
##  5           1            0.436
##  6           0            0.374
##  7           0            0.344
##  8           0            0.268
##  9           0            0.366
## 10           1            0.246
## 11           0            0.181
```


```
## # A tibble: 300 × 2
##    tv_license tv_license_pred
##         &lt;dbl&gt;           &lt;dbl&gt;
##  1          1          0.202 
##  2          1          0.134 
##  3          1          0.644 
##  4          0          0.0302
##  5          1          0.464 
##  6          0          0.495 
##  7          1          0.936 
##  8          0          0.293 
##  9          1          0.644 
## 10          0          0.0687
## # ℹ 290 more rows
```


]



---

# Model fit/accuracy

.pull-left-small[

#### `\(K\)`-fold Cross-Validation

One of the ways of getting a better representation of model accuracy (a measure less influenced by the idiosyncrasies in our sample) is the __K-fold Cross-validation__.

* Take a unique subset of data to 'hold out' of our model estimation.
* Estimate our model on the remaining data.
* Check the accuracy of this model on our hold out data.
* Repeat this `\(k\)` times and then look at the average accuracy and standard error. (Normally `\(k\)` = 5 or 10)

]


.pull-right-big[

&lt;br&gt;

&lt;img src="images/k-fold.png" width="100%" /&gt;

]


---

# Model fit/accuracy

.pull-left[

#### `\(K\)`-fold Cross-Validation

`\(K\)`-fold Cross-Validation is very easy to perform in `R` using the `performance` package.

* Set a randomiser seed if you need your results to be replicable.
* Use the `performance_accuracy` function to perform k-fold cross-validation.

__Results__

* The average accuracy for our model was 63.5% — about 4 percentage points worse than our raw accuracy.
* Average standard error estimate of the accuracy was around 5%

]


.pull-right[

&lt;br&gt;


```r
# Set seed - Because the unique subsets are random
# for demonstration purposes I want to make sure 
# the they are always the same
set.seed(306)

# Use the performance package to perform k-fold 
# cross-validation
performance::performance_accuracy(alien_model, k = 5)
```

```
## # Accuracy of Model Predictions
## 
## Accuracy (95% CI): 63.50% [56.66%, 67.97%]
## Method: Area under Curve
```

]


---

class: inverse, middle

Week 9: Logistic Regression — Part V
# Logistic regression assumptions.


---

# Assumptions


.pull-left[

* __Linearity__

* __Homoscedasticity__

* __No outliers or leverage points__

* __Normality of residuals__

* __No multicollinearity__

]

.pull-right[



]


---

# Assumptions


.pull-left[

* __Linearity__

* .grey[Homoscedasticity]

* __No outliers or leverage points__

* .grey[Normality of residuals]

* __No multicollinearity__

]

.pull-right[



]

---

# Assumptions


.pull-left[

* __Linearity__

* __No outliers or leverage points__

* __No multicollinearity__


]

.pull-right[



]

---

# Assumptions


.pull-left[

* __Linearity__

* __No outliers or leverage points__

* __No multicollinearity__

* __No autocorrelation__

]

.pull-right[



]


---

# Assumptions


.pull-left-small[

* __Linearity__

  * For continuous predictors only
  * Is a straight line the best fit to the data or would a curved line fit better?

* No outliers or leverage points

* No multicollinearity

* No autocorrelation

]

.pull-right-big[


```r
conspiracy_data %&gt;%
  # Get predicted logodds
  mutate(
    pred_alien_logodds = predict(alien_model,
                                 type = "link",
                                 newdata = conspiracy_data)
  ) %&gt;%
  # Plot logodds against continuous predictors
  ggplot() +
  geom_point(aes(x = rage, y = pred_alien_logodds)) +
  geom_smooth(aes(x = rage, y = pred_alien_logodds), method = "lm")
```

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-65-1.png" width="700" height="320" /&gt;


]


---

# Assumptions


.pull-left-small[

* __Linearity__

  * For continuous predictors only
  * Is a straight line the best fit to the data or would a curved line fit better?
  * Can use something called a Box-Tidwell test to check whether non-linearity is significant

* No outliers or leverage points

* No multicollinearity

* No autocorrelation

]

.pull-right-big[


```r
conspiracy_data %&gt;%
  # Get predicted logodds
  mutate(
    pred_alien_logodds = predict(alien_model,
                                 type = "link",
                                 newdata = conspiracy_data)
  ) %&gt;%
  # Plot logodds against continuous predictors
  ggplot() +
  geom_point(aes(x = openness, y = pred_alien_logodds)) +
  geom_smooth(aes(x = openness, y = pred_alien_logodds), method = "lm")
```

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-66-1.png" width="700" height="320" /&gt;


]


---
background-color: white 


# Assumptions


.pull-left-small[

* Linearity

* __No outliers or leverage points__

  * Just like in multiple linear regression, we can use our Cook's Distance plots to try and identify any potential outliers.

* No multicollinearity

* No autocorrelation

]

.pull-right-big[


```r
plot(alien_model, which = 4)
```

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-67-1.png" width="700" height="400" /&gt;


]


---

background-color: white 

# Assumptions


.pull-left-small[

* Linearity

* __No outliers or leverage points__

  * Just like in multiple linear regression, we can use our Cook's Distance plots to try and identify any potential outliers.

* No multicollinearity

* No autocorrelation

]

.pull-right-big[


```r
plot(alien_model, which = 5)
```

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-68-1.png" width="700" height="400" /&gt;


]

---

# Assumptions


.pull-left-small[

* Linearity

* __No outliers or leverage points__

  * Just like in multiple linear regression, we can use our Cook's Distance plots to try and identify any potential outliers.
  * We can also use the convenience function `check_outliers` in the `performance` package

* No multicollinearity

* No autocorrelation

]

.pull-right-big[


```r
performance::check_outliers(alien_model)
```

```
## OK: No outliers detected.
## - Based on the following method and threshold: cook (0.8).
## - For variable: (Whole model)
```


]


---

# Assumptions


.pull-left-small[

* Linearity

* No outliers or leverage points

* __No multicollinearity__

  * Reminder: multicollinearity occurs when our independent variables are too closely related (linearly).
  * We can check using VIFs, the same was as with standard Multiple Linear Regression, using either the `car` or `performance` package. All of our independent variables' VIF should be less than 5.

* No autocorrelation

]

.pull-right-big[


```r
car::vif(alien_model)
```

```
##                 GVIF Df GVIF^(1/(2*Df))
## rage        1.397780  1        1.182277
## games       1.242034  1        1.114466
## hedqual_rec 1.311885  6        1.022880
## openness    1.109380  1        1.053271
```

```r
performance::multicollinearity(alien_model)
```

```
## # Check for Multicollinearity
## 
## Low Correlation
## 
##         Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI
##         rage 1.40 [1.32, 1.50]         1.18      0.72     [0.67, 0.76]
##        games 1.24 [1.18, 1.33]         1.11      0.81     [0.75, 0.85]
##  hedqual_rec 1.31 [1.24, 1.41]         1.15      0.76     [0.71, 0.81]
##     openness 1.11 [1.06, 1.19]         1.05      0.90     [0.84, 0.94]
```


]

---

# Assumptions


.pull-left-small[

* Linearity

* No outliers or leverage points

* No multicollinearity

* __No autocorrelation__

]

.pull-right-big[

#### What is autocorrelation?

An assumption of general linear models that we have only briefly touched on (but is explored a lot in Advanced Quants methods' topics on multilevel modelling) is __autocorrelation__.

Just like our independent variables must be independent, our __observations should be independent__. Observations can become autocorrelated in a number of ways:



]

---

# Assumptions


.pull-left-small[

* Linearity

* No outliers or leverage points

* No multicollinearity

* __No autocorrelation__

]

.pull-right-big[

#### What is autocorrelation?

An assumption of general linear models that we have only briefly touched on (but is explored a lot in Advanced Quants methods' topics on multilevel modelling) is __autocorrelation__.

Just like our independent variables must be independent, our __observations should be independent__. Observations can become autocorrelated in a number of ways:

* Multiple observations of the same person (over time, or in error)


]


---

# Assumptions


.pull-left-small[

* Linearity

* No outliers or leverage points

* No multicollinearity

* __No autocorrelation__

]

.pull-right-big[

#### What is autocorrelation?

An assumption of general linear models that we have only briefly touched on (but is explored a lot in Advanced Quants methods' topics on multilevel modelling) is __autocorrelation__.

Just like our independent variables must be independent, our __observations should be independent__. Observations can become autocorrelated in a number of ways:

* Multiple observations of the same person (over time, or in error)

* Nested data structure (e.g. pupils in the same school will be more similar to each other than pupils in different schools)


]


---

# Assumptions


.pull-left-small[

* Linearity

* No outliers or leverage points

* No multicollinearity

* __No autocorrelation__

]

.pull-right-big[

#### What is autocorrelation?

An assumption of general linear models that we have only briefly touched on (but is explored a lot in Advanced Quants methods' topics on multilevel modelling) is __autocorrelation__.

Just like our independent variables must be independent, our __observations should be independent__. Observations can become autocorrelated in a number of ways:

* Multiple observations of the same person (over time, or in error)

* Nested data structure (e.g. pupils in the same school will be more similar to each other than pupils in different schools)

* An important variable has not been included in the model, but is still exhibited in the data


]


---

# Assumptions


.pull-left-small[

* Linearity

* No outliers or leverage points

* No multicollinearity

* __No autocorrelation__

  * Does spending more time with a Teaching Assistant improve a student's grades?

]

.pull-right-big[

#### Simpson's Paradox

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-71-1.png" width="700" height="400" /&gt;


]


---

# Assumptions


.pull-left-small[

* Linearity

* No outliers or leverage points

* No multicollinearity

* __No autocorrelation__

  * Does spending more time with a Teaching Assistant improve a student's grades?

]

.pull-right-big[

#### Simpson's Paradox

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-72-1.png" width="700" height="400" /&gt;


]

---

# Assumptions


.pull-left-small[

* Linearity

* No outliers or leverage points

* No multicollinearity

* __No autocorrelation__

  * Does spending more time with a Teaching Assistant improve a student's grades?

]

.pull-right-big[

#### Simpson's Paradox

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-73-1.png" width="700" height="400" /&gt;


]


---

class: middle

# Assumptions: Autocorrelation


.pull-left[


```r
lm_without_class &lt;- lm(sp_data, 
                    formula = student_grade ~ time_with_ta)

summary(lm_without_class)
```

```
## 
## Call:
## lm(formula = student_grade ~ time_with_ta, data = sp_data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -12.9330  -3.7937  -0.0315   3.3053  13.1065 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  73.57857    1.36450  53.924  &lt; 2e-16 ***
## time_with_ta -0.17174    0.06152  -2.792  0.00643 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 5.629 on 88 degrees of freedom
## Multiple R-squared:  0.08135,	Adjusted R-squared:  0.07091 
## F-statistic: 7.793 on 1 and 88 DF,  p-value: 0.006433
```

]

.pull-right[


```r
lm_with_class &lt;- lm(sp_data, 
                    formula = student_grade ~ time_with_ta + class)

summary(lm_with_class)
```

```
## 
## Call:
## lm(formula = student_grade ~ time_with_ta + class, data = sp_data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -10.4383  -1.5488   0.3002   2.0286   6.6004 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)          66.49609    0.92949   71.54   &lt;2e-16 ***
## time_with_ta          0.82230    0.07913   10.39   &lt;2e-16 ***
## classIntro to Quant -12.23828    1.18316  -10.34   &lt;2e-16 ***
## classPrinciples I   -26.07610    1.86911  -13.95   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.14 on 86 degrees of freedom
## Multiple R-squared:  0.7207,	Adjusted R-squared:  0.711 
## F-statistic: 73.97 on 3 and 86 DF,  p-value: &lt; 2.2e-16
```


]

.center[ __The best defense against autocorrelation is knowing your data, its structure, and possible sources of omitted variable bias, as well as your subject area and theory!__ ]

---

class: middle

# Assumptions: Autocorrelation


.pull-left[

However, we can test for autocorrelation using `car`'s Durbin Watson test...


```r
car::durbinWatsonTest(lm_without_class)
```

```
##  lag Autocorrelation D-W Statistic p-value
##    1       0.2000415      1.559888   0.028
##  Alternative hypothesis: rho != 0
```

```r
performance::check_autocorrelation(lm_without_class)
```

```
## Warning: Autocorrelated residuals detected (p = 0.044).
```

]

.pull-right[

Or `performance`'s `check_autocorrelation` test. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;


```r
car::durbinWatsonTest(lm_with_class)
```

```
##  lag Autocorrelation D-W Statistic p-value
##    1     -0.03969624      2.026359   0.876
##  Alternative hypothesis: rho != 0
```

```r
performance::check_autocorrelation(lm_with_class)
```

```
## OK: Residuals appear to be independent and not autocorrelated (p = 0.882).
```


]

.center[ __p &lt; 0.05 means we reject the idea that cases are independent (not autocorrelated).__ ]


---

# Assumptions


.pull-left-small[

* Linearity

* No outliers or leverage points

* No multicollinearity

* __No autocorrelation__

  * Observations are not independent.
  * Check using a Durbin-Watson test (but best to __know your data well__!)

]

.pull-right-big[

#### Simpson's Paradox

&lt;img src="week-09-logistic-regression_files/figure-html/unnamed-chunk-78-1.png" width="700" height="400" /&gt;


]


---

class: middle

## Reminder - Cheat sheet on violated assumptions.

.pull-left[

* __Linearity__

This means that your estimates will be over- and under-estimated at different parts of the line. For logistic regression, you can only resolve this by fitting a curvilinear model (non-linear relationship between X and Y) — bit more advanced but not too difficult!

* __Outliers and leverage points__

Outliers and leverage points can generally have an undue influence on the slope in a regression. Remove any error-based outliers (e.g. someone enters their age as 400 instead of 40). Compare results with 'true' outliers included and excluded to see how they differ, present both. 


]

.pull-right[



]


---

class: middle

## Reminder - Cheat sheet on violated assumptions.

.pull-left[

* __Linearity__

This means that your estimates will be over- and under-estimated at different parts of the line. For logistic regression, you can only resolve this by fitting a curvilinear model (non-linear relationship between X and Y) — bit more advanced but not too difficult!

* __Outliers and leverage points__

Outliers and leverage points can generally have an undue influence on the slope in a regression. Remove any error-based outliers (e.g. someone enters their age as 400 instead of 40). Compare results with 'true' outliers included and excluded to see how they differ, present both. 


]

.pull-right[

* __No multicollinearity__

Try removing highly correlated variables and re-running the model to see how estimates change. Are the two+ variables measuring the same underlying process, are they poorly measured, is data highly aggregated? Report models with one variable removed to show bias caused. 




]




---

class: middle

## Reminder - Cheat sheet on violated assumptions.

.pull-left[

* __Linearity__

This means that your estimates will be over- and under-estimated at different parts of the line. For logistic regression, you can only resolve this by fitting a curvilinear model (non-linear relationship between X and Y) — bit more advanced but not too difficult!

* __Outliers and leverage points__

Outliers and leverage points can generally have an undue influence on the slope in a regression. Remove any error-based outliers (e.g. someone enters their age as 400 instead of 40). Compare results with 'true' outliers included and excluded to see how they differ, present both. 


]

.pull-right[

* __No multicollinearity__

Try removing highly correlated variables and re-running the model to see how estimates change. Are the two+ variables measuring the same underlying process, are they poorly measured, is data highly aggregated? Report models with one variable removed to show bias caused. 

* __No autocorrelation__

Report Durbin-Watson test. Consider the source of autocorrelation. If from a measured variable (e.g. group), consider adding to the model. For very large numbers of groups (e.g. households), you may need a more complex __fixed effects__ or __multilevel model__.


]



---

class: inverse, middle

Week 9: Logistic Regression — Summary &amp; Practical

# Summary &amp; Practical.


---

class: middle

# Summary

* Logistic regression __allows us to explore any research question that uses a dependent variable that can be expressed as a binary outcome__ with all the power of multiple linear regression.

--

* This works through the Maximum Likelihood Estimator using the odds, log odds, and logistic sigmoid function to __create a best fitting logistic sigmoid curve__ to our underlying data.

--

* Logistic regression models can be estimated in `R` using the `glm()` function. Our results can be communicated as odds ratios by exponentiating our estimated change in log odds. Further, we can communicate our findings using the `ggeffects` package to produce predicted probabilities.

--

* We can check our model fit using a range of tools, including pseudo- `\(R^2\)`s, model accuracy, and k-fold cross-validation.

--

* We have a reduced number of assumptions to check for logistic regression, but we can check them using the `predict` function and `ggplot` (linearity with log odds), `plot()` function (outliers and leverage points), VIF statistics (multicollinearity), and Durbin-Watson test (autocorrelation). Autocorrelation also applies to OLS multiple linear models.



---

class: middle

# R Practical

#### What state-level variables are predictive of the presence of Neo-Nazi and anti-immigration hate groups in the United States?

* Download the `week-9-exercise.zip` file from Blackboard. Unzip the file and open the .Rproj file and associated .Rmd worksheet. Follow the steps to explore the above research question. 
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"sealed": false,
"ratio": "16:9",
"self_contained": true,
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<style>
.my-header {
	background-color: #440099;
	position: fixed;
	top: 0px;
	left: 0px;
	height: 70px;
	width: 100%;
	text-align: left;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.inverse)' +
    // add additional classes to exclude here, e.g.
    // ':not(.inverse)' +
    ':not(.hide-logo)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="my-header"></div>';
  });
</script>


<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
