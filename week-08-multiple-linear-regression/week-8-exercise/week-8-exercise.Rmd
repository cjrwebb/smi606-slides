---
title: "Week 8 Exercise"
author: "Calum Webb"
date: "13/11/2021"
output: pdf_document
---

## How large is the gender pay gap in the UK?

In this week's practical example, we will follow researchers using real data from the Labour Force Survey 2018 to explore the gender pay gap in the UK.

The Labour Force Survey is a repeated cross-sectional survey that includes data from a stratified sample of respondents and aims for these to be representative of the general population of working-age adults in the UK. The LFS' methodology at the time only allowed respondents to answer either 'male' or 'female', or allowed them to refuse to answer, and did not differentiate between sex and gender in its survey. Participants with 'missing' responses, including those who chose not to answer some questions, are not included in this teaching dataset extract. Given the mode of questionnaire delivery, where respondents are asked their gender or where interviewers record the participant's gender as the gender they felt they present as (yes, really, this happens!), responses should be considered as participant's gender rather than their sex assigned at birth. This limits our analysis of the real data to identifying any gender pay gap between people whose gender aligns to either male or female, and prevents us from exploring how pay may differ between these groups and people who may have a gender identity other than male or female.

We start by reading in the data and loading required packages. Remember to check the variable names and descriptions in the `codebook.xlsx` file.

```{r}

library(car)
library(tidyverse)
library(janitor)

lfs_data <- read_csv("lfs_sample.csv")


```

---

The researchers start by creating a bivariate linear regression model to find out what the gender pay gap is without taking account of any other possible indirect pathways or confounding variables.

```{r}

model_1 <- lm(data = lfs_data,
              formula = grsswk ~ sexx)

summary(model_1)

```

* Describe the size of the gender pay gap based on this model and whether it was statistically significant or not.





---

The researchers want to change the variables they are using so that men are the reference category, and women are the category coded as "1".

```{r}

lfs_data <- lfs_data %>%
  mutate(
    female = case_when(is.na(sexx) ~ NA_real_,
                       sexx == "female" ~ 1,
                       TRUE ~ 0)
  )

```

* Re-run the model with this new variable where men are coded 0 and women are coded as 1. Save it as `model_2` and create a summary of the output. Describe the results.

```{r}

# Write your own code here!

```

---

The researchers now add some additional independent variables to the model, hours worked per week (`ttushr`), number of children aged 0-4 (`numchild04`), and simplified highest qualification held (`levqul15`).

```{r}

model_3 <- lm(data = lfs_data,
              formula = grsswk ~ female + numchild04 + ttushr + levqul15)

summary(model_3)

```

* How does the estimate for the `female` variable change now that these additional variables are included?






* What value has been chosen as the reference category for the levqul15 variable? Hint: use `tabyl()` to see a summary of the number of people in each category.

```{r}

# Write your own code here

```

* Do you think the researchers should change their reference category for highest qualification? If so, which category do you think they should choose and why?







---

The researchers decide to recode their `levqul15` variable so that "NQF Level 4 and above" (university-level education) is the reference category. They use the `factor()` and `relevel()` functions to do this.

```{r}

lfs_data <- lfs_data %>%
  mutate(
    levqul15_fct = relevel(factor(levqul15), ref = "NQF Level 4 and above")
  )

```

* Write the code to re-run the multiple regression model with the new `levqul15_fct` variable created above. Save the new model as `model_4` and print a summary using `summary()`.

```{r}

# Write your own code here

```

* Interpret the effect of each different kind of qualification on weekly pay relative to the new reference category of university level (Level 4) qualifications. E.g. "Respondents with no qualifications had weekly pay that was on average Â£X lower/higher than respondents with university level qualifications..."





To visualise the differences between educational group, while controlling for gender, number of dependent children, and hours worked, the researchers use the `ggeffects` package to create a prediction plot:

```{r}

library(effects)
library(ggeffects)

# ggeffect will create predictions at mean values of the other variables
# and varying values of the chosen variable (here: education); 
# The plot() function then plots this as a forest plot (though if you)
# leave it out it will just give you the values in text form
ggeffect(model_4, terms = "levqul15_fct")
ggeffect(model_4, terms = "levqul15_fct") %>% plot() 


```

* Add the following function to the end of the ggeffect(model_4, terms = "levqul15_fct") %>% plot() code and check what changes: + coord_flip(). 

```{r}

# Write your answer in R code here

```

* How does this change help the communication of the plot?




* What was the mean predicted income for people with NQF level 4 and above qualifications?



* Now use the ggeffect code as a template to get the predicted pay for different numbers of dependent children by changing the terms argument to refer to the `numchild04` variable.

```{r}

# Write your R code here

```

* What happens to the standard error (the shaded area) around our predictions for different numbers of dependent children as the number of dependent children increases? Why does this happen and how does it relate to the p-value associated with the numchild04 variable in the model?






---

Lastly, the researchers decide to add whether the respondent is a manager, foreman/supervisor, or neither a manager or supervisor as a predictor of gross weekly pay in the model, using the `manager` variable.

```{r}

model_5 <- lm(data = lfs_data,
              formula = grsswk ~ female + numchild04 + ttushr + levqul15_fct + manager)

summary(model_5)

```


* What is the reference category chosen automatically by `R` for the manager variable (Hint: Check using a `tabyl()`)






* Use the `relevel` and `factor` functions to create a new variable based on the `manager` variable that has "Not manager or supervisor" as the reference category.

```{r}

# Write your own code in here

```

* Re-run the `model_5` multiple regression model but this time use the new manager variable that you created above, where the reference category is "Not manager or supervisor". Name this regression model model_6.

```{r}

# Write your own code in here

```

* Report the results from the model in full, describe the findings across all variables as well as the size and significance of the gender pay gap after controlling for all of these additional factors.










* Are there any other variables in the codebook that may confound the relationship between gender and pay? If so, justify why you think the one you chose might be a potential confounder.








---

Now, the researchers decide to assess whether their model violates any assumptions (linearity, heteroscedasticity, non-normality of residuals, outliers/leverage points, and multicollinearity).

The researchers decide to use a residuals versus fitted values plot to explore whether there was any evidence of non-normality in the model.

NB: They use model_5 as the results from these plots would be identical, even if the reference category has changed.

```{r}

# Residuals Versus Fitted Values Plot
plot(model_5, which = 1)

```

* Interpret the residuals versus fitted values plot (you can use the cheat sheet in the lecture slides). Was there any evidence of non-normality? If so, how severe does it look and what consequences might it have on the model's accuracy and bias?








---

Next, the researchers chose to inspect the homoscedasticity of the residuals using a scale-location plot.

```{r}

# Scale-Location Plot
plot(model_5, which = 3)

```

* Is there evidence of heteroscedasticity among the residuals? If so, what shape does this heteroscedasticity take and what affect might this have on the model estimates.








---

The researchers then checked whether there was evidence of significant outliers in the model using Cook's distance plots.


```{r}

# Cook's Distance Plot
plot(model_5, which = 4)

# Residuals versus leverage plot
plot(model_5, which = 5)

```

* Based on the above plots, was there any evidence of potentially significant outliers? If so, what is the observation row number of these outliers?








---

The normality of the residuals were then checked using a Q-Q plot.

```{r}

# Q-Q plot
plot(model_5, which = 2)

```

* Was there any evidence of non-normality of residuals based on the Q-Q plot? If so, what impact might this have on our model results (Hint: use the Cheat Sheet in the lecture slides for week 7 or week 8)








---

Finally, the researchers explore whether there may be any multicollinearity present among their independent variables using the `vif` function from the `car` package.


```{r}

# Variance Inflation Factor
car::vif(model_5)

```

* Do the VIF/GVIF values suggest there is any degree of multicollinearity that could bias the model estimates? Why/why not? 







---

## Week 8 Challenges

* Try rerunning the last model in the script but with a logged (`log()`) or square-root (`sqrt()`) version of the dependent variable (`grsswk`). Does this change the model R-squared or any of the assumption checks? If so, how do these change and what would the possible consequences be.


* Try adding the variable you identified as an additional potential confounder to the model: how does adding this variable change the findings? Can you use a prediction plot to show the predicted means for each value of your chosen variable?


* Conduct a similar analysis to the above, but this time explore the pay gap between ethnic groups in the UK. 





